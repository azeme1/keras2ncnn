{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import imageio\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, InputSpec, DepthwiseConv2D, BatchNormalization, Activation, Conv2D, Add, Conv2DTranspose\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.backend import int_shape, permute_dimensions\n",
    "from collections import OrderedDict\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, SeparableConv2D\n",
    "from tensorflow.keras.initializers import RandomNormal, RandomUniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_layer(model_config, src_name, dst_name):\n",
    "    for layer_item in model_config['input_layers']:\n",
    "        input_condition = layer_item[0] == src_name\n",
    "        if input_condition:\n",
    "            # print('Rename Input:: ', layer_item[0])\n",
    "            layer_item[0] = dst_name\n",
    "\n",
    "    for layer_item in model_config['output_layers']:\n",
    "        output_condition = layer_item[0] == src_name\n",
    "        if output_condition:\n",
    "            # print('Rename Output:: ', layer_item[0])\n",
    "            layer_item[0] = dst_name\n",
    "    #     print(rename_condition,  layer_list[0])\n",
    "\n",
    "    for layer_item in model_config['layers']:\n",
    "        name_condition = layer_item['name'] == src_name\n",
    "        if name_condition:\n",
    "            # print('Rename Layers:: name', layer_item['name'])\n",
    "            layer_item['name'] = dst_name\n",
    "\n",
    "        name_condition = layer_item['config']['name'] == src_name\n",
    "        if name_condition:\n",
    "            # print('Rename Layers Config:: config', layer_item['config']['name'])\n",
    "            layer_item['config']['name'] = dst_name\n",
    "            #             print('               Rename Layers Config:: config', layer_item['config']['name'])\n",
    "\n",
    "        if len(layer_item['inbound_nodes']) > 0:\n",
    "            for item in layer_item['inbound_nodes'][0]:\n",
    "                inbound_condition = item[0] == src_name\n",
    "                if inbound_condition:\n",
    "                    # print('Rename Layers Inbound::', item[0])\n",
    "                    item[0] = dst_name\n",
    "    return model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv2D_config_template = {\n",
    "    'name': '_node_name',\n",
    "    'class_name': 'Conv2D',\n",
    "    'config': {'name': '_node_name',\n",
    "    'trainable': True,\n",
    "    'dtype': 'float32',\n",
    "    'filters': 1,\n",
    "    'kernel_size': (1, 1),\n",
    "    'strides': (1, 1),\n",
    "    'padding': 'same',\n",
    "    'data_format': 'channels_last',\n",
    "    'dilation_rate': (1, 1),\n",
    "    'activation': 'linear',\n",
    "    'use_bias': True,\n",
    "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
    "     'config': {'seed': None}},\n",
    "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
    "    'kernel_regularizer': None,\n",
    "    'bias_regularizer': None,\n",
    "    'activity_regularizer': None,\n",
    "    'kernel_constraint': None,\n",
    "    'bias_constraint': None},\n",
    "   'name': '_node_name',\n",
    "   'inbound_nodes': [[['_in_node_name', 0, 0, {}]]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder = Input((32, 32, 3), name='data')\n",
    "x = a = Conv2D(4, (7,7), padding='same', name='src_1', bias_initializer=RandomNormal())(placeholder)\n",
    "x = BatchNormalization(name='src_2', \n",
    "                       beta_initializer=RandomNormal(),\n",
    "                       gamma_initializer=RandomNormal(),\n",
    "                       moving_mean_initializer=RandomNormal(),\n",
    "                       moving_variance_initializer=RandomUniform(1,2))(x)\n",
    "# x = Add()([a, x])\n",
    "src_model = Model(placeholder, x, name='src_model')\n",
    "\n",
    "placeholder = Input((32, 32, 3), name='data')\n",
    "x = Conv2D(4, (7, 7), padding='same', name='dst_1')(placeholder)\n",
    "dst_model = Model(placeholder, x, name='dst_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight, bias = src_model.get_layer('src_1').get_weights()\n",
    "gamma, beta, mean, var = src_model.get_layer('src_2').get_weights()\n",
    "eps = src_model.get_layer('src_2').get_config()['epsilon']\n",
    "a = gamma / np.sqrt(var + eps)\n",
    "weight = weight*a.reshape((1,1,-1,1))\n",
    "bias = a*(bias - mean) + beta\n",
    "dst_model.get_layer('dst_1').set_weights([weight, bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = np.random.uniform(size=(1,) + dst_model.input_shape[1:])\n",
    "print(np.abs(dst_model.predict(x_in) - src_model.predict(x_in)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_Conv2DBatchNormalization_Conv2D(src_model, dst_model, transfer_rule):\n",
    "    layer_c = src_model.get_layer(transfer_rule['src_c'])\n",
    "    weigths_c = layer_c.get_weights()\n",
    "    layer_b = src_model.get_layer(transfer_rule['src_b'])\n",
    "    weigths_b = layer_b.get_weights()\n",
    "    \n",
    "    eps = layer_b.get_config()['epsilon']\n",
    "    weight, bias = weigths_c\n",
    "    gamma, beta, mean, var = weigths_b\n",
    "    \n",
    "    a = gamma / np.sqrt(var + eps)\n",
    "    weight = weight*a\n",
    "    bias = a*(bias - mean) + beta\n",
    "    \n",
    "    dst_model.get_layer(transfer_rule['dst']).set_weights([weight, bias])\n",
    "\n",
    "def get_outbound_nodes(keras_config):\n",
    "    outbound_dict = {}\n",
    "    index_dict = {}\n",
    "    for _i, _layer in enumerate(keras_config['layers']):\n",
    "        out_node_name = _layer['name']\n",
    "        index_dict[out_node_name] = _i\n",
    "        if len(_layer['inbound_nodes']) == 0:\n",
    "            continue\n",
    "        in_node_name = _layer['inbound_nodes'][0][0][0]\n",
    "        if in_node_name in outbound_dict:\n",
    "            outbound_dict[in_node_name] += [out_node_name]\n",
    "        else:\n",
    "            outbound_dict[in_node_name] = [out_node_name]\n",
    "        \n",
    "    return outbound_dict, index_dict\n",
    "    \n",
    "def detect_transform_Conv2DBatchNormalization(keras_config):\n",
    "    index_list = []\n",
    "    outbound_dict, index_dict = get_outbound_nodes(keras_config)\n",
    "    for i, item in enumerate(keras_config['layers']):\n",
    "        if item['class_name'] == 'BatchNormalization':\n",
    "            in_node_name = item['inbound_nodes'][0][0][0]\n",
    "            in_node_class_name = keras_config['layers'][index_dict[in_node_name]]['class_name']\n",
    "            if in_node_class_name == 'Conv2D':\n",
    "                if len(outbound_dict[in_node_name]) == 1:\n",
    "                    index_list.append(i)\n",
    "    return index_list\n",
    "\n",
    "def apply_transform_Conv2DBatchNormalization(keras_config):\n",
    "    index_list = detect_transform_Conv2DBatchNormalization(keras_config)\n",
    "    weight_transfer_rule_dict = {}\n",
    "    while len(index_list) > 0:\n",
    "        i = index_list[0]\n",
    "        r_layer_config = keras_config['layers'].pop(i)\n",
    "        src_name = r_layer_config['name']\n",
    "        dst_name = r_layer_config['inbound_nodes'][0][0][0]\n",
    "        keras_config = rename_layer(keras_config, src_name, dst_name)\n",
    "        merged_dst = dst_name + '_M'\n",
    "        keras_config = rename_layer(keras_config, dst_name, merged_dst)\n",
    "        weight_transfer_rule_dict[merged_dst] = {'transfer_call': transfer_Conv2DBatchNormalization_Conv2D,\n",
    "                                                             'src_c': dst_name, \n",
    "                                                             'src_b': src_name, \n",
    "                                                             'dst':merged_dst}        \n",
    "        index_list = detect_transform_Conv2DBatchNormalization(keras_config)\n",
    "    return keras_config, weight_transfer_rule_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_weights(src_model, dst_model, weight_transfer_rule_dict):\n",
    "    for dst_layer in tqdm(dst_model.layers):\n",
    "        if dst_layer.name in weight_transfer_rule_dict:\n",
    "            transfer_rule = weight_transfer_rule_dict[dst_layer.name]\n",
    "            func = transfer_rule['transfer_call']\n",
    "            func(src_model, dst_model, transfer_rule)\n",
    "        else:\n",
    "            src_model.get_layer(dst_layer.name).set_weights(dst_layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_model_config, weight_transfer_rule_dict = apply_transform_Conv2DBatchNormalization(src_model.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_model = Model.from_config(dst_model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_weights(src_model, dst_model, weight_transfer_rule_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = np.random.uniform(size=(1,) + dst_model.input_shape[1:])\n",
    "print(np.abs(dst_model.predict(x_in) - src_model.predict(x_in)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
