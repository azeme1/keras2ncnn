{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\olga\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\olga\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\olga\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\olga\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\olga\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\olga\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\olga\\Miniconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\olga\\Miniconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\olga\\Miniconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\olga\\Miniconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\olga\\Miniconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\olga\\Miniconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import imageio\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, InputSpec, DepthwiseConv2D, BatchNormalization, Activation, Conv2D, Add, Conv2DTranspose\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.backend import int_shape, permute_dimensions\n",
    "from collections import OrderedDict\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, SeparableConv2D\n",
    "from tensorflow.keras.initializers import RandomNormal, RandomUniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_layer(model_config, src_name, dst_name):\n",
    "    for layer_item in model_config['input_layers']:\n",
    "        input_condition = layer_item[0] == src_name\n",
    "        if input_condition:\n",
    "            # print('Rename Input:: ', layer_item[0])\n",
    "            layer_item[0] = dst_name\n",
    "\n",
    "    for layer_item in model_config['output_layers']:\n",
    "        output_condition = layer_item[0] == src_name\n",
    "        if output_condition:\n",
    "            # print('Rename Output:: ', layer_item[0])\n",
    "            layer_item[0] = dst_name\n",
    "    #     print(rename_condition,  layer_list[0])\n",
    "\n",
    "    for layer_item in model_config['layers']:\n",
    "        name_condition = layer_item['name'] == src_name\n",
    "        if name_condition:\n",
    "            # print('Rename Layers:: name', layer_item['name'])\n",
    "            layer_item['name'] = dst_name\n",
    "\n",
    "        name_condition = layer_item['config']['name'] == src_name\n",
    "        if name_condition:\n",
    "            # print('Rename Layers Config:: config', layer_item['config']['name'])\n",
    "            layer_item['config']['name'] = dst_name\n",
    "            #             print('               Rename Layers Config:: config', layer_item['config']['name'])\n",
    "\n",
    "        if len(layer_item['inbound_nodes']) > 0:\n",
    "            for item in layer_item['inbound_nodes'][0]:\n",
    "                inbound_condition = item[0] == src_name\n",
    "                if inbound_condition:\n",
    "                    # print('Rename Layers Inbound::', item[0])\n",
    "                    item[0] = dst_name\n",
    "    return model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DepthwiseConv2D_config_template = {'name': '_node_name',\n",
    " 'class_name': 'DepthwiseConv2D',\n",
    " 'config': {'name': '_node_name',\n",
    "  'trainable': True,\n",
    "  'dtype': 'float32',\n",
    "  'kernel_size': (1, 1),\n",
    "  'strides': (1, 1),\n",
    "  'padding': 'same',\n",
    "  'data_format': 'channels_last',\n",
    "  'dilation_rate': (1, 1),\n",
    "  'activation': 'linear',\n",
    "  'use_bias': False,\n",
    "  'bias_initializer': {'class_name': 'Zeros', 'config': {'dtype': 'float32'}},\n",
    "  'bias_regularizer': None,\n",
    "  'activity_regularizer': None,\n",
    "  'bias_constraint': None,\n",
    "  'depth_multiplier': 1,\n",
    "  'depthwise_initializer': {'class_name': 'GlorotUniform',\n",
    "   'config': {'seed': None, 'dtype': 'float32'}},\n",
    "  'depthwise_regularizer': None,\n",
    "  'depthwise_constraint': None},\n",
    " 'inbound_nodes': [[['_in_node_name', 0, 0, {}]]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\olga\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\olga\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\olga\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "placeholder = a = Input((32, 32, 3), name='data')\n",
    "x = BatchNormalization(name='src', \n",
    "                       beta_initializer=RandomNormal(),\n",
    "                       gamma_initializer=RandomNormal(),\n",
    "                       moving_mean_initializer=RandomNormal(),\n",
    "                       moving_variance_initializer=RandomUniform(1,2))(placeholder)\n",
    "# x = Add()([a, x])\n",
    "src_model = Model(placeholder, x, name='src_model')\n",
    "\n",
    "placeholder = Input((32, 32, 3), name='data')\n",
    "x = DepthwiseConv2D((1, 1), padding='same', name='dst')(placeholder)\n",
    "dst_model = Model(placeholder, x, name='dst_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma, beta, mean, var = src_model.get_layer('src').get_weights()\n",
    "eps = src_model.get_layer('src').get_config()['epsilon']\n",
    "a = gamma / np.sqrt(var + eps)\n",
    "weight = a.reshape((1,1,-1,1))\n",
    "bias = -a*mean + beta\n",
    "dst_model.get_layer('dst').set_weights([weight, bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6063215e-06\n"
     ]
    }
   ],
   "source": [
    "x_in = np.random.uniform(size=(1,) + dst_model.input_shape[1:])\n",
    "print(np.abs(dst_model.predict(x_in) - src_model.predict(x_in)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_BatchNormalization_DepthwiseConv2D(src_model, dst_model, transfer_rule):\n",
    "    gamma, beta, mean, var = src_model.get_layer(transfer_rule['src']).get_weights()\n",
    "    eps = src_model.get_layer(transfer_rule['src']).get_config()['epsilon']\n",
    "    a = gamma / np.sqrt(var + eps)\n",
    "    weight = a.reshape((1,1,-1,1))\n",
    "    bias = -a*mean + beta\n",
    "    \n",
    "    dst_model.get_layer(transfer_rule['dst']).set_weights([weight, bias])\n",
    "    \n",
    "def detect_transform_BatchNormalization_DepthwiseConv2D(keras_config):\n",
    "    index_list = []\n",
    "    for i, item in enumerate(keras_config['layers']):\n",
    "        if item['class_name'] == 'BatchNormalization':\n",
    "            index_list.append(i)\n",
    "    return index_list\n",
    "\n",
    "def apply_transform_BatchNormalization_DepthwiseConv2D(keras_config):\n",
    "    index_list = detect_transform_BatchNormalization_DepthwiseConv2D(keras_config)\n",
    "    weight_transfer_rule_dict = {}\n",
    "    while len(index_list) > 0:\n",
    "        i = index_list[0]\n",
    "        r_layer_config = keras_config['layers'].pop(i)\n",
    "        i_layer_config = deepcopy(DepthwiseConv2D_config_template)\n",
    "        \n",
    "        i_layer_config['inbound_nodes'] = r_layer_config['inbound_nodes']\n",
    "        i_layer_config['config']['name'] = i_layer_config['name'] = r_layer_config['name']\n",
    "        i_layer_config['config']['use_bias'] = True\n",
    "        i_layer_config['config']['kernel_size'] = (1, 1) \n",
    "        keras_config['layers'].insert(i, i_layer_config)\n",
    "        weight_transfer_rule_dict[i_layer_config['name']] = {'transfer_call': transfer_BatchNormalization_DepthwiseConv2D,\n",
    "                                                             'src': r_layer_config['name'],\n",
    "                                                             'dst': i_layer_config['name']}       \n",
    "        index_list = detect_transform_BatchNormalization_DepthwiseConv2D(keras_config)\n",
    "    return keras_config, weight_transfer_rule_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_weights(src_model, dst_model, weight_transfer_rule_dict):\n",
    "    for dst_layer in tqdm(dst_model.layers):\n",
    "        if dst_layer.name in weight_transfer_rule_dict:\n",
    "            transfer_rule = weight_transfer_rule_dict[dst_layer.name]\n",
    "            func = transfer_rule['transfer_call']\n",
    "            func(src_model, dst_model, transfer_rule)\n",
    "        else:\n",
    "            src_model.get_layer(dst_layer.name).set_weights(dst_layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_model_config, weight_transfer_rule_dict = apply_transform_BatchNormalization_DepthwiseConv2D(src_model.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\olga\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\olga\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "dst_model = Model.from_config(dst_model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 42.52it/s]\n"
     ]
    }
   ],
   "source": [
    "transfer_weights(src_model, dst_model, weight_transfer_rule_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6752393e-06\n"
     ]
    }
   ],
   "source": [
    "x_in = np.random.uniform(size=(1,) + dst_model.input_shape[1:])\n",
    "print(np.abs(dst_model.predict(x_in) - src_model.predict(x_in)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.000820159912 < 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
